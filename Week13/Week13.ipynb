{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "tensor([ 10,  12,  14,  16,  18,  20,  22,  24,  26,  28,  30,  32,  34,  36,\n",
      "         38,  40,  42,  44,  46,  48,  50,  52,  54,  56,  58,  60,  62,  64,\n",
      "         66,  68,  70,  72,  74,  76,  78,  80,  82,  84,  86,  88,  90,  92,\n",
      "         94,  96,  98, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "    Create the following tensors:\n",
    "        1. 3D tensor of shape 20x30x40 with all values = 0\n",
    "        2. 1D tensor containing the even numbers between 10 and 100\n",
    "\"\"\"\n",
    "\n",
    "tensor_3d = torch.zeros(30, 30, 40) \n",
    "tensor_1d = torch.arange(10, 101, 2)\n",
    "print(tensor_3d)\n",
    "print(tensor_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7336, 0.7770, 0.0345, 0.7204, 0.9569, 0.1462],\n",
      "        [0.6092, 0.9192, 0.0028, 0.8278, 0.0428, 0.9686],\n",
      "        [0.0042, 0.6610, 0.8509, 0.5545, 0.7163, 0.8979],\n",
      "        [0.4312, 0.0486, 0.5114, 0.6781, 0.2036, 0.3422]])\n",
      "torch.Size([4, 6])\n",
      "tensor(12.6390)\n",
      "tensor([1.7782, 2.4059, 1.3996, 2.7809, 1.9197, 2.3548])\n",
      "tensor([3.3687, 3.3705, 3.6848, 2.2151])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    x = torch.rand(4, 6)\n",
    "    Calculate:\n",
    "        1. Sum of all elements of x\n",
    "        2. Sum of the columns of x  (result is a 6-element tensor)\n",
    "        3. Sum of the rows of x   (result is a 4-element tensor)\n",
    "\"\"\"\n",
    "x = torch.rand(4, 6)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "sum_all = x.sum()\n",
    "print(sum_all)\n",
    "\n",
    "# columns (dim=0), rows (dim=1)\n",
    "sum_cols = torch.sum(x, dim=0)\n",
    "print(sum_cols)\n",
    "\n",
    "sum_rows = torch.sum(x, dim=1)\n",
    "print(sum_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9995)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Calculate cosine similarity between 2 1D tensor:\n",
    "    x = torch.tensor([0.1, 0.3, 2.3, 0.45])\n",
    "    y = torch.tensor([0.13, 0.23, 2.33, 0.45])\n",
    "\"\"\"\n",
    "x = torch.tensor([0.1, 0.3, 2.3, 0.45])\n",
    "y = torch.tensor([0.13, 0.23, 2.33, 0.45])\n",
    "\n",
    "cosine_similarity = torch.nn.functional.cosine_similarity(x, y, dim=0)\n",
    "print(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4552, -0.3140,  0.9258])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Calculate cosine similarity between 2 2D tensor:\n",
    "    x = torch.tensor([[ 0.2714, 1.1430, 1.3997, 0.8788],\n",
    "                      [-2.2268, 1.9799, 1.5682, 0.5850],\n",
    "                      [ 1.2289, 0.5043, -0.1625, 1.1403]])\n",
    "    y = torch.tensor([[-0.3299, 0.6360, -0.2014, 0.5989],\n",
    "                      [-0.6679, 0.0793, -2.5842, -1.5123],\n",
    "                      [ 1.1110, -0.1212, 0.0324, 1.1277]])\n",
    "\"\"\"\n",
    "x = torch.tensor([[ 0.2714, 1.1430, 1.3997, 0.8788],\n",
    "                    [-2.2268, 1.9799, 1.5682, 0.5850],\n",
    "                    [ 1.2289, 0.5043, -0.1625, 1.1403]])\n",
    "y = torch.tensor([[-0.3299, 0.6360, -0.2014, 0.5989],\n",
    "                    [-0.6679, 0.0793, -2.5842, -1.5123],\n",
    "                    [ 1.1110, -0.1212, 0.0324, 1.1277]])\n",
    "\n",
    "cosine_similarity = torch.nn.functional.cosine_similarity(x, y, dim=1) # columns (dim=0), rows (dim=1)\n",
    "print(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "torch.Size([12])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    x = torch.tensor([[ 0,  1],\n",
    "                      [ 2,  3],\n",
    "                      [ 4,  5],\n",
    "                      [ 6,  7],\n",
    "                      [ 8,  9],\n",
    "                      [10, 11]])\n",
    "    Make x become 1D tensor\n",
    "    Then, make that 1D tensor become 3x4 2D tensor \n",
    "\"\"\"\n",
    "x = torch.tensor([[ 0,  1],\n",
    "                    [ 2,  3],\n",
    "                    [ 4,  5],\n",
    "                    [ 6,  7],\n",
    "                    [ 8,  9],\n",
    "                    [10, 11]])\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# view method in PyTorch is used to reshape a tensor without changing its data\n",
    "tensor_1d = x.view(-1)\n",
    "print(tensor_1d)\n",
    "print(tensor_1d.shape)\n",
    "\n",
    "tensor_2d = x.view(3, 4)\n",
    "print(tensor_2d)\n",
    "print(tensor_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1988, 0.7988, 0.7694,  ..., 0.1909, 0.0912, 0.0341],\n",
      "          [0.0336, 0.8306, 0.7410,  ..., 0.2502, 0.2544, 0.2148],\n",
      "          [0.0683, 0.7969, 0.9576,  ..., 0.1406, 0.6662, 0.9199],\n",
      "          ...,\n",
      "          [0.8436, 0.9784, 0.8556,  ..., 0.0362, 0.4907, 0.7176],\n",
      "          [0.2111, 0.1260, 0.8130,  ..., 0.8251, 0.9704, 0.7360],\n",
      "          [0.0730, 0.0282, 0.4977,  ..., 0.6892, 0.3262, 0.3149]],\n",
      "\n",
      "         [[0.9801, 0.8748, 0.1943,  ..., 0.0477, 0.3547, 0.5902],\n",
      "          [0.4666, 0.1928, 0.7507,  ..., 0.9977, 0.2023, 0.1289],\n",
      "          [0.2914, 0.9041, 0.0359,  ..., 0.1182, 0.2253, 0.5671],\n",
      "          ...,\n",
      "          [0.9236, 0.1257, 0.3322,  ..., 0.0434, 0.2708, 0.9755],\n",
      "          [0.8176, 0.9305, 0.7250,  ..., 0.4590, 0.1757, 0.2768],\n",
      "          [0.4847, 0.7720, 0.9188,  ..., 0.4349, 0.5843, 0.5685]],\n",
      "\n",
      "         [[0.0476, 0.8762, 0.5678,  ..., 0.2414, 0.6461, 0.0930],\n",
      "          [0.2818, 0.7393, 0.5937,  ..., 0.2383, 0.5308, 0.4688],\n",
      "          [0.4634, 0.6723, 0.2074,  ..., 0.8254, 0.3995, 0.9589],\n",
      "          ...,\n",
      "          [0.5417, 0.7253, 0.3479,  ..., 0.9201, 0.5847, 0.7423],\n",
      "          [0.2476, 0.9400, 0.5236,  ..., 0.5992, 0.4048, 0.8467],\n",
      "          [0.1595, 0.8697, 0.8242,  ..., 0.9955, 0.8223, 0.5392]]]])\n",
      "torch.Size([1, 3, 1080, 1920])\n",
      "tensor([[[[5.3947e-01, 6.8822e-01, 6.8565e-01,  ..., 9.1034e-01,\n",
      "           1.3497e-01, 8.5202e-01],\n",
      "          [6.3277e-01, 4.4953e-01, 9.6563e-01,  ..., 8.0221e-01,\n",
      "           9.5835e-01, 2.4206e-02],\n",
      "          [2.3991e-01, 2.3121e-02, 3.1990e-01,  ..., 7.5234e-01,\n",
      "           4.4022e-01, 5.4565e-01],\n",
      "          ...,\n",
      "          [2.5923e-01, 9.3938e-02, 8.1993e-01,  ..., 8.2246e-01,\n",
      "           4.3658e-01, 3.0874e-01],\n",
      "          [7.6528e-01, 4.4678e-01, 3.0299e-01,  ..., 8.5652e-04,\n",
      "           8.6327e-01, 4.8229e-01],\n",
      "          [9.6543e-01, 3.3671e-01, 6.9202e-01,  ..., 7.1957e-01,\n",
      "           9.8460e-01, 4.8431e-01]],\n",
      "\n",
      "         [[4.1399e-01, 4.1953e-01, 9.7357e-01,  ..., 2.0995e-01,\n",
      "           1.3956e-01, 9.5475e-01],\n",
      "          [5.3120e-01, 9.2276e-01, 1.0441e-01,  ..., 8.9355e-01,\n",
      "           4.1484e-01, 6.1742e-01],\n",
      "          [4.7129e-01, 4.1452e-01, 1.2250e-01,  ..., 8.4724e-01,\n",
      "           8.2163e-01, 6.6464e-01],\n",
      "          ...,\n",
      "          [9.3647e-01, 5.1120e-01, 4.6936e-02,  ..., 7.1532e-01,\n",
      "           2.5009e-01, 3.5464e-01],\n",
      "          [1.6683e-01, 1.8277e-01, 4.5748e-01,  ..., 2.8532e-01,\n",
      "           3.9743e-01, 6.0078e-01],\n",
      "          [4.1138e-01, 2.6389e-02, 1.9384e-01,  ..., 7.9490e-01,\n",
      "           9.7833e-01, 1.7548e-03]],\n",
      "\n",
      "         [[3.9693e-02, 6.0815e-01, 7.0803e-01,  ..., 6.7549e-01,\n",
      "           9.3474e-01, 2.1615e-01],\n",
      "          [7.8375e-01, 1.2682e-01, 8.8448e-01,  ..., 9.2710e-02,\n",
      "           9.1613e-01, 3.3114e-01],\n",
      "          [2.8921e-01, 2.1690e-01, 4.5719e-01,  ..., 9.5775e-02,\n",
      "           4.4046e-01, 1.7453e-01],\n",
      "          ...,\n",
      "          [3.9434e-01, 3.7467e-01, 2.3545e-01,  ..., 4.2137e-01,\n",
      "           1.4672e-01, 1.3997e-01],\n",
      "          [4.7627e-01, 4.1186e-01, 7.1025e-01,  ..., 7.5509e-01,\n",
      "           1.0017e-01, 6.9785e-01],\n",
      "          [1.9533e-01, 7.2007e-01, 4.5890e-01,  ..., 5.4888e-02,\n",
      "           4.2999e-01, 5.2407e-01]]]])\n",
      "torch.Size([1, 3, 720, 1280])\n",
      "torch.Size([1, 3, 1080, 1920])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "concat() received an invalid combination of arguments - got (Tensor, Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)\n * (tuple of Tensors tensors, name dim, *, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(resized_y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# torch.cat function in PyTorch is used to concatenate (join) tensors along a specified dimension\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m concatenated_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_x_4d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresized_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(concatenated_tensor)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(concatenated_tensor\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mTypeError\u001b[0m: concat() received an invalid combination of arguments - got (Tensor, Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)\n * (tuple of Tensors tensors, name dim, *, Tensor out = None)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    x = torch.rand(3, 1080, 1920)\n",
    "    y = torch.rand(3, 720, 1280)\n",
    "    Do the following tasks:\n",
    "        1. Make x become 1x3x1080x1920 4D tensor\n",
    "        2. Make y become 1x3x720x1280 4D tensor\n",
    "        3. Resize y to make it have the same size as x\n",
    "        4. Join them to become 2x3x1080x1920 tensor\n",
    "\"\"\"\n",
    "\n",
    "# torch.rand function in PyTorch generates a tensor filled with random numbers drawn from \n",
    "# a uniform distribution on the interval ([0, 1)).\n",
    "x = torch.rand(3, 1080, 1920)\n",
    "y = torch.rand(3, 720, 1280)\n",
    "\n",
    "# unsqueeze method in PyTorch is used to add a singleton dimension (a dimension of size 1) \n",
    "# to a tensor at a specified position\n",
    "tensor_x_4d = x.unsqueeze(0)\n",
    "print(tensor_x_4d)\n",
    "print(tensor_x_4d.shape)\n",
    "\n",
    "tensor_y_4d = y.unsqueeze(0)\n",
    "print(tensor_y_4d)\n",
    "print(tensor_y_4d.shape)\n",
    "\n",
    "# torch.nn.functional.interpolate function in PyTorch is used for resizing tensors\n",
    "resized_y = torch.nn.functional.interpolate(tensor_y_4d, size=(1080, 1920), mode=\"bilinear\", align_corners=False)\n",
    "print(resized_y.shape)\n",
    "\n",
    "# torch.cat function in PyTorch is used to concatenate (join) tensors along a specified dimension\n",
    "concatenated_tensor = torch.concat((tensor_x_4d, resized_y), dim=0)\n",
    "print(concatenated_tensor)\n",
    "print(concatenated_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
